{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730769ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39524e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/files/98/98-0.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ba5b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = request.urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "668714fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = response.read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19d57a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "737ad7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'A', 'Tale', 'of', 'Two', 'Cities', ',', 'by', 'Charles', 'Dickens', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.', 'You', 'may', 'copy', 'it', ',', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org', '.', 'If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States', ',', 'you', 'will', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'eBook', '.', 'Title', ':', 'A', 'Tale', 'of', 'Two', 'Cities', 'A', 'Story', 'of', 'the', 'French', 'Revolution', 'Author', ':', 'Charles', 'Dickens', 'Release', 'Date', ':', 'January', ',', '1994', '[', 'eBook', '#', '98', ']', '[', 'Most', 'recently', 'updated', ':', 'December', '20', ',', '2020', ']', 'Language', ':', 'English', 'Character', 'set', 'encoding', ':', 'UTF-8', 'Produced', 'by', ':', 'Judith', 'Boss', 'and', 'David', 'Widger', '*', '*', '*', 'START', 'OF', 'THE', 'PROJECT', 'GUTENBERG', 'EBOOK', 'A', 'TALE', 'OF', 'TWO', 'CITIES', '*', '*', '*', 'A', 'TALE', 'OF', 'TWO', 'CITIES', 'A', 'STORY', 'OF', 'THE', 'FRENCH', 'REVOLUTION', 'By', 'Charles', 'Dickens', 'CONTENTS', 'Book', 'the', 'First', '--', 'Recalled', 'to', 'Life', 'CHAPTER', 'I', 'The', 'Period', 'CHAPTER', 'II']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d77159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup\n",
    "#Preprocessing - RE to clean any html tags or unnecessary char \n",
    "#PoS tagging \n",
    "#.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce09d85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cacti'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "porter.stem('cacti')  #happiness joyous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2ab493a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joy'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.stem import LancasterStemmer\n",
    "lancaster = LancasterStemmer()\n",
    "lancaster.stem('joyous')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfef16f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sing'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.stem import RegexpStemmer\n",
    "Regex = RegexpStemmer('ing$')\n",
    "Regex.stem('singing') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "176f2caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sing'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.stem import SnowballStemmer\n",
    "snow = SnowballStemmer('english')\n",
    "snow.stem('singing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f724cd",
   "metadata": {},
   "source": [
    "### Porting an entire paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eff8ef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "text = \"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us, we wer all going direct to Heaven, we were all going direct the other way--in short, the period was so far like the present period, that some of its noisiest authorities insisted on its being received, for good or for evil, in the superlative degree of comparison only.\"\n",
    "stemmed = [porter.stem(tokens) for tokens in text.split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88c996f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'wa', 'the', 'best', 'of', 'times,', 'it', 'wa', 'the', 'worst', 'of', 'times,', 'it', 'wa', 'the', 'age', 'of', 'wisdom,', 'it', 'wa']\n"
     ]
    }
   ],
   "source": [
    "print(stemmed[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c57c2c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "lancaster = LancasterStemmer()\n",
    "text = \"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us, we wer all going direct to Heaven, we were all going direct the other way--in short, the period was so far like the present period, that some of its noisiest authorities insisted on its being received, for good or for evil, in the superlative degree of comparison only.\"\n",
    "stemmed = [lancaster.stem(tokens) for tokens in text.split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9e37b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'was', 'the', 'best', 'of', 'times,', 'it', 'was', 'the', 'worst', 'of', 'times,', 'it', 'was', 'the', 'ag', 'of', 'wisdom,', 'it', 'was']\n"
     ]
    }
   ],
   "source": [
    "print(stemmed[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a37709c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "  \n",
    "print(lemmatizer.lemmatize(\"am\", pos = 'v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f237f1",
   "metadata": {},
   "source": [
    "#  text to numerical vector conversion binary vectorization format used in word embedded pretrained models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e561dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "315e1d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(binary=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus=[\"NLP is awsome\",\"Learning vector conversion\",\"Count Vectorizer\"]\n",
    "vect.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7edf1269",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8a56f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awsome:0\n",
      "conversion:1\n",
      "count:2\n",
      "is:3\n",
      "learning:4\n",
      "nlp:5\n",
      "vector:6\n",
      "vectorizer:7\n"
     ]
    }
   ],
   "source": [
    "for key in sorted(vocab.keys()):\n",
    "    print(\"{}:{}\".format(key,vocab[key]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0ec9cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transform([\"I have a awsome NLP company worth an awsome one Billion\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c29d71f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity=cosine_similarity(vect.transform([\"ML is an elective subject in VIT\"]).toarray(),vect.transform([\"NLP is an attractive career now\"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46aafeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
